
I tested 3 deadline-sensitive statements for the 3rd benchmark of HA-4584.

1. HDFS datanode write
    6 suspicious loops
- 2: reported bug
- 4: false positives - small loops

2. heartbeat from datanode to namenode
    5 suspicious loops
- 2: one new bug
- 3: false positives - small loops

3. HDFS namenode write (ie, General write)
    6 suspicious loops
- 2: one new bug - PS: This is almost same as the 4th benchmark I am doing, so I am very sure this is a new bug, it is caused by large numbers of block reports waiting for NameNode's handling.
- 4: false positives 
- 3: small loops
- 1: asynchronous write









======
Affect Write OP - only bug loop
FINAL - static I/O pruning
CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-227;                #reported bug, call the next
CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset-getGenerationStampFromFile-70;         #reported bug, called by the above
CL3: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-227;       #same as all above, also affect the normal writes(but different threads) see PS
CL3: org.apache.hadoop.hdfs.server.datanode.FSDataset-getGenerationStampFromFile-70;#same as all above,also affect the normal writes(but different threads) see PS
	PS: 
	CL3: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-227;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-221;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-221;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume-getBlockInfo-519;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo-680;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;
	|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;
	|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getNextVolume--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-writeToBlock-1386;org.apache.hadoop.hdfs.server.datanode.BlockReceiver-<init>-99;org.apache.hadoop.hdfs.server.datanode.DataXceiver-writeBlock-299;org.apache.hadoop.hdfs.server.datanode.DataXceiver-run-107;java.lang.Thread-run-745;
	|org.apache.hadoop.hdfs.server.datanode.FSDataset-writeToBlock-1365;org.apache.hadoop.hdfs.server.datanode.BlockReceiver-<init>-99;org.apache.hadoop.hdfs.server.datanode.DataXceiver-writeBlock-299;org.apache.hadoop.hdfs.server.datanode.DataXceiver-run-107;java.lang.Thread-run-745;
	|org.apache.hadoop.hdfs.server.datanode.FSDataset-finalizeBlockInternal--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-finalizeBlock-1516;org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder-run-855;java.lang.Thread-run-745;
	CL3: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-227;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-221;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-221;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume-getBlockInfo-519;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo-680;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;
	|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;
	|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getNextVolume--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-writeToBlock-1386;org.apache.hadoop.hdfs.server.datanode.BlockReceiver-<init>-99;org.apache.hadoop.hdfs.server.datanode.DataXceiver-writeBlock-299;org.apache.hadoop.hdfs.server.datanode.DataXceiver-run-107;java.lang.Thread-run-745;
	|org.apache.hadoop.hdfs.server.datanode.FSDataset-writeToBlock-1365;org.apache.hadoop.hdfs.server.datanode.BlockReceiver-<init>-99;org.apache.hadoop.hdfs.server.datanode.DataXceiver-writeBlock-299;org.apache.hadoop.hdfs.server.datanode.DataXceiver-run-107;java.lang.Thread-run-745;
	|org.apache.hadoop.hdfs.server.datanode.FSDataset-setVisibleLength--1;org.apache.hadoop.hdfs.server.datanode.BlockReceiver-receivePacket-479;org.apache.hadoop.hdfs.server.datanode.BlockReceiver-receiveBlock-532;org.apache.hadoop.hdfs.server.datanode.DataXceiver-writeBlock-398;org.apache.hadoop.hdfs.server.datanode.DataXceiver-run-107;java.lang.Thread-run-745;|

//CL2~3: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo-679;   #small loop - #volumes = 2(from my config)
//CL2~3: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getCapacity-664;    #small loop - #volumes = 2(from my config)
//CL2~3: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getNextVolume-645;  #small loop - while (true) { return/throw }
//CL2~3: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getRemaining-672;   #small loop - #volumes = 2(from my config)
summary - 12(#static codepoints=6) from 18 (#static codepoints=10)


=======
Affect Heartbeat OP - 2 new bug loop (in one bug)
FINAL
simplechainbugpool(whole chain's lastcallstacks) - has 4 loops (#static codepoints=4)
// two new bug loops - ie, DataBlockScanner#run  PS - the fisrt one is recursively, so it will be overlooked in FINAL, but actually we need to count
//CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-220;|org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;|org.apache.hadoop.hdfs.server.datanode.FSDataset-getRemaining-985;|
CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-227;|org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;|org.apache.hadoop.hdfs.server.datanode.FSDataset-getRemaining-985;|
	PS - 
	medianchainbugpool(whole chain's fullcallstacks) - all 7 loop instances
	CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-220;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-221;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume-getBlockInfo-519;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo-680;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getRemaining--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getRemaining-985;org.apache.hadoop.hdfs.server.datanode.DataNode-offerService-885;org.apache.hadoop.hdfs.server.datanode.DataNode-run-1421;java.lang.Thread-run-745;|
	CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-220;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume-getBlockInfo-519;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo-680;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getRemaining--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getRemaining-985;org.apache.hadoop.hdfs.server.datanode.DataNode-offerService-885;org.apache.hadoop.hdfs.server.datanode.DataNode-run-1421;java.lang.Thread-run-745;|
	CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-227;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-221;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-221;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume-getBlockInfo-519;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo-680;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getRemaining--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getRemaining-985;org.apache.hadoop.hdfs.server.datanode.DataNode-offerService-885;org.apache.hadoop.hdfs.server.datanode.DataNode-run-1421;java.lang.Thread-run-745;|
	CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-227;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-221;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume-getBlockInfo-519;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo-680;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getRemaining--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getRemaining-985;org.apache.hadoop.hdfs.server.datanode.DataNode-offerService-885;org.apache.hadoop.hdfs.server.datanode.DataNode-run-1421;java.lang.Thread-run-745;|
	CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir-getBlockInfo-227;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume-getBlockInfo-519;org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo-680;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getRemaining--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getRemaining-985;org.apache.hadoop.hdfs.server.datanode.DataNode-offerService-885;org.apache.hadoop.hdfs.server.datanode.DataNode-run-1421;java.lang.Thread-run-745;|
	// these two are small
	//CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo-679;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-init-203;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner-run-600;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getRemaining--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getRemaining-985;org.apache.hadoop.hdfs.server.datanode.DataNode-offerService-885;org.apache.hadoop.hdfs.server.datanode.DataNode-run-1421;java.lang.Thread-run-745;|
	//CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getNextVolume-645;org.apache.hadoop.hdfs.server.datanode.FSDataset-writeToBlock-1386;org.apache.hadoop.hdfs.server.datanode.BlockReceiver-<init>-99;org.apache.hadoop.hdfs.server.datanode.DataXceiver-writeBlock-299;org.apache.hadoop.hdfs.server.datanode.DataXceiver-run-107;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getNextVolume--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-writeToBlock-1386;org.apache.hadoop.hdfs.server.datanode.BlockReceiver-<init>-99;org.apache.hadoop.hdfs.server.datanode.DataXceiver-writeBlock-299;org.apache.hadoop.hdfs.server.datanode.DataXceiver-run-107;java.lang.Thread-run-745;|org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getRemaining--1;org.apache.hadoop.hdfs.server.datanode.FSDataset-getRemaining-985;org.apache.hadoop.hdfs.server.datanode.DataNode-offerService-885;org.apache.hadoop.hdfs.server.datanode.DataNode-run-1421;java.lang.Thread-run-745;|
// these two are small loops 
//CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getBlockInfo-679;|org.apache.hadoop.hdfs.server.datanode.FSDataset-getBlockReport-1637;|org.apache.hadoop.hdfs.server.datanode.FSDataset-getRemaining-985;|
//CL2: org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet-getNextVolume-645;|org.apache.hadoop.hdfs.server.datanode.FSDataset-writeToBlock-1386;|org.apache.hadoop.hdfs.server.datanode.FSDataset-getRemaining-985;|
---------------
// not IO-inside - ie, couldn't see in the FINAL result
//CL2: org.apache.hadoop.hdfs.server.namenode.FSNamesystem-heartbeatCheck-3281;|org.apache.hadoop.hdfs.server.namenode.FSNamesystem-heartbeatCheck-3279;|org.apache.hadoop.hdfs.server.namenode.FSNamesystem-handleHeartbeat-2546;|
-------
///// already pruned by modifying happens-before ThdEnter ->-> MsgProcEnter xx | MsgProcEnter xx | MsgProcEnter xx 
/////CL2: org.apache.hadoop.hdfs.server.common.UpgradeObjectCollection-getDistributedUpgrades-117;|org.apache.hadoop.hdfs.server.namenode.FSNamesystem-startDistributedUpgradeIfNeeded-5115;|org.apache.hadoop.hdfs.server.namenode.FSNamesystem-getDistributedUpgradeCommand-5103;|
	PS - 
	CL2: org.apache.hadoop.hdfs.server.common.UpgradeObjectCollection-getDistributedUpgrades-117(jx:LOOP);org.apache.hadoop.hdfs.server.common.UpgradeManager-getDistributedUpgrades-56;org.apache.hadoop.hdfs.server.common.UpgradeManager-initializeUpgrade-67;org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode-startUpgrade-57(jx:LOCK<UpgradeManagerNamenode>);org.apache.hadoop.hdfs.server.namenode.FSNamesystem-startDistributedUpgradeIfNeeded-5115;org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-leave-4712;org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-checkMode-4791;org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-setBlockTotal-4810;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-setBlockTotal-5011;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-initialize-390;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-<init>-358;org.apache.hadoop.hdfs.server.namenode.NameNode-initialize-276;org.apache.hadoop.hdfs.server.namenode.NameNode-<init>-497;org.apache.hadoop.hdfs.server.namenode.NameNode-createNameNode-1268;org.apache.hadoop.hdfs.server.namenode.NameNode-main-1277;
	|org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode-startUpgrade--1(jx:LOCK<UpgradeManagerNamenode>);org.apache.hadoop.hdfs.server.namenode.FSNamesystem-startDistributedUpgradeIfNeeded-5115;org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-leave-4712(jx:LOCK<$SafeModeInfo>);org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-checkMode-4791;org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-setBlockTotal-4810(jx:LOCK<$SafeModeInfo>);org.apache.hadoop.hdfs.server.namenode.FSNamesystem-setBlockTotal-5011;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-initialize-390;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-<init>-358;org.apache.hadoop.hdfs.server.namenode.NameNode-initialize-276;org.apache.hadoop.hdfs.server.namenode.NameNode-<init>-497;org.apache.hadoop.hdfs.server.namenode.NameNode-createNameNode-1268;org.apache.hadoop.hdfs.server.namenode.NameNode-main-1277;
	|org.apache.hadoop.hdfs.server.common.UpgradeManager-getBroadcastCommand--1(jx:LOCK<UpgradeManagerNamenode>);org.apache.hadoop.hdfs.server.namenode.FSNamesystem-getDistributedUpgradeCommand-5103;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-handleHeartbeat-2605;org.apache.hadoop.hdfs.server.namenode.NameNode-sendHeartbeat-979;sun.reflect.GeneratedMethodAccessor2-invoke--1;sun.reflect.DelegatingMethodAccessorImpl-invoke-43;java.lang.reflect.Method-invoke-606;org.apache.hadoop.ipc.RPC$Server-call-563;org.apache.hadoop.ipc.Server$Handler$1-run-1388;org.apache.hadoop.ipc.Server$Handler$1-run-1384;java.security.AccessController-doPrivileged--2;javax.security.auth.Subject-doAs-415;org.apache.hadoop.security.UserGroupInformation-doAs-1059;org.apache.hadoop.ipc.Server$Handler-run-1382;|
	CL2: org.apache.hadoop.hdfs.server.common.UpgradeObjectCollection-getDistributedUpgrades-117;org.apache.hadoop.hdfs.server.common.UpgradeManager-getDistributedUpgrades-56;org.apache.hadoop.hdfs.server.common.UpgradeManager-initializeUpgrade-67;org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode-startUpgrade-57;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-startDistributedUpgradeIfNeeded-5115;org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-leave-4712;org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-checkMode-4791;org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-setBlockTotal-4810;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-setBlockTotal-5011;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-initialize-390;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-<init>-358;org.apache.hadoop.hdfs.server.namenode.NameNode-initialize-276;org.apache.hadoop.hdfs.server.namenode.NameNode-<init>-497;org.apache.hadoop.hdfs.server.namenode.NameNode-createNameNode-1268;org.apache.hadoop.hdfs.server.namenode.NameNode-main-1277;|org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode-startUpgrade--1;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-startDistributedUpgradeIfNeeded-5115;org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-leave-4712;org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-checkMode-4791;org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo-setBlockTotal-4810;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-setBlockTotal-5011;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-initialize-390;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-<init>-358;org.apache.hadoop.hdfs.server.namenode.NameNode-initialize-276;org.apache.hadoop.hdfs.server.namenode.NameNode-<init>-497;org.apache.hadoop.hdfs.server.namenode.NameNode-createNameNode-1268;org.apache.hadoop.hdfs.server.namenode.NameNode-main-1277;|org.apache.hadoop.hdfs.server.common.UpgradeManager-getBroadcastCommand--1;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-getDistributedUpgradeCommand-5103;org.apache.hadoop.hdfs.server.namenode.FSNamesystem-handleHeartbeat-2605;org.apache.hadoop.hdfs.server.namenode.NameNode-sendHeartbeat-979;sun.reflect.NativeMethodAccessorImpl-invoke0--2;sun.reflect.NativeMethodAccessorImpl-invoke-57;sun.reflect.DelegatingMethodAccessorImpl-invoke-43;java.lang.reflect.Method-invoke-606;org.apache.hadoop.ipc.RPC$Server-call-563;org.apache.hadoop.ipc.Server$Handler$1-run-1388;org.apache.hadoop.ipc.Server$Handler$1-run-1384;java.security.AccessController-doPrivileged--2;javax.security.auth.Subject-doAs-415;org.apache.hadoop.security.UserGroupInformation-doAs-1059;org.apache.hadoop.ipc.Server$Handler-run-1382;|

	
==========================
Affect namenode write OP - 2 new bugs
FINAL simple_bugpool
CL2: org.apache.hadoop.hdfs.server.namenode.FSNamesystem-processReport-3440;
		LOOP - org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport(Lorg/apache/hadoop/hdfs/protocol/DatanodeID;Lorg/apache/hadoop/hdfs/protocol/BlockListAsLongs;)V:3440, Time-consumingOps(13):[4689:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.isOn@< Application, Ljava/io/PrintStream, print(Ljava/lang/String;)V >, 1628:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage@< Application, Ljava/io/File, exists()Z >, 1629:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage@< Application, Ljava/io/File, mkdir()Z >, 1632:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage@< Application, Ljava/io/File, exists()Z >, 249:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString@< Application, Ljava/io/DataOutput, writeShort(I)V >, 278:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 280:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 281:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 283:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 284:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 285:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 442:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.datanode.DataStorage.corruptPreUpgradeStorage@< Application, Ljava/io/File, exists()Z >, 600:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.setFields-org.apache.hadoop.hdfs.server.namenode.FSImage.writeCheckpointTime@< Application, Ljava/io/DataOutputStream, writeLong(J)V >]
		for (Block b : toRemove) {
			removeStoredBlock(b, node);
		}
CL2: org.apache.hadoop.hdfs.server.namenode.FSNamesystem-processReport-3443;
		LOOP - org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport(Lorg/apache/hadoop/hdfs/protocol/DatanodeID;Lorg/apache/hadoop/hdfs/protocol/BlockListAsLongs;)V:3443, Time-consumingOps(14):[163:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.CorruptReplicasMap.addToCorruptReplicasMap-org.apache.hadoop.ipc.Server.getRemoteIp@< Application, Ljava/net/Socket, getInetAddress()Ljava/net/InetAddress; >, 4689:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.isOn@< Application, Ljava/io/PrintStream, print(Ljava/lang/String;)V >, 1628:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage@< Application, Ljava/io/File, exists()Z >, 1629:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage@< Application, Ljava/io/File, mkdir()Z >, 1632:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage@< Application, Ljava/io/File, exists()Z >, 249:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString@< Application, Ljava/io/DataOutput, writeShort(I)V >, 278:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 280:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 281:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 283:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 284:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 285:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage-org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData-org.apache.hadoop.io.UTF8.writeString-org.apache.hadoop.io.UTF8.writeChars@< Application, Ljava/io/DataOutput, writeByte(I)V >, 442:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.datanode.DataStorage.corruptPreUpgradeStorage@< Application, Ljava/io/File, exists()Z >, 600:org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processReport-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.markBlockAsCorrupt-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeStoredBlock-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.decrementSafeBlockCount-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode-org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startDistributedUpgradeIfNeeded-org.apache.hadoop.hdfs.server.namenode.UpgradeManagerNamenode.startUpgrade-org.apache.hadoop.hdfs.server.common.Storage.writeAll-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.write-org.apache.hadoop.hdfs.server.namenode.FSImage.setFields-org.apache.hadoop.hdfs.server.namenode.FSImage.writeCheckpointTime@< Application, Ljava/io/DataOutputStream, writeLong(J)V >]
		for (Block b : toAdd) {
			addStoredBlock(b, node, null);
		}
//CL2~4: org.apache.hadoop.hdfs.server.namenode.FSDirectory-mkdirs-947;                               #small loop - from DFSClient <- DistributedFileSystem <- Shell? 
//CL2~4: org.apache.hadoop.hdfs.server.namenode.FSEditLog$EditLogFileOutputStream-write-154;          #small loop - log a hdfs operation's info, so limited
//CL2~4: org.apache.hadoop.hdfs.server.namenode.FSEditLog-logEdit-908;                                #small loop - from "dfs.name.dir" for redundency
	   public void logOpenFile(String path, INodeFileUnderConstruction newNode) 
                   throws IOException {
        ...
        logEdit(OP_ADD,
            new ArrayWritable(UTF8.class, nameReplicationPair), 
            new ArrayWritable(Block.class, newNode.getBlocks()),
            newNode.getPermissionStatus(),
            new UTF8(newNode.getClientName()),
            new UTF8(newNode.getClientMachine()));
	 +
	 synchronized void logEdit(byte op, Writable ... writables) {
	    assert this.getNumEditStreams() > 0 : "no editlog streams";
	    long start = FSNamesystem.now();
	 908for (int idx = 0; idx < editStreams.size(); idx++) {                    
	      EditLogOutputStream eStream = editStreams.get(idx);
	      try {
	        eStream.write(op, writables);
	      } 
     +
		void write(byte op, Writable ... writables) throws IOException {
	      write(op);
	 154  for(Writable w : writables) {
	        w.write(bufCurrent);
	      }
	    }
//CL2~3: org.apache.hadoop.hdfs.server.namenode.LeaseManager-checkLeases-380;                     #asyncd write
     the IO is org.apache.hadoop.hdfs.server.namenode.FSNamesystem.internalReleaseLeaseOne-org.apache.hadoop.hdfs.server.namenode.FSNamesystem.finalizeINodeFileUnderConstruction-org.apache.hadoop.hdfs.server.namenode.FSDirectory.closeFile-org.apache.hadoop.hdfs.server.namenode.FSEditLog.logCloseFile-org.apache.hadoop.hdfs.server.namenode.FSEditLog.logEdit-org.apache.hadoop.hdfs.server.namenode.FSEditLog$EditLogFileOutputStream.write-org.apache.hadoop.ipc.RPC$Invocation.write-org.apache.hadoop.io.ObjectWritable.writeObject@< Application, Ljava/io/DataOutput, writeBoolean(Z)V >,
         public void run() {
      for(; fsnamesystem.isRunning(); ) {
        synchronized(fsnamesystem) {
          checkLeases();
        }

        try {
          Thread.sleep(2000);
        } catch(InterruptedException ie) {
          if (LOG.isDebugEnabled()) {
            LOG.debug(name + " is interrupted", ie);
          }
        }
      }
     +
     synchronized void checkLeases() {
    for(; sortedLeases.size() > 0; ) {
      final Lease oldest = sortedLeases.first();
      if (!oldest.expiredHardLimit()) {
        return;
      }

      LOG.info("Lease " + oldest + " has expired hard limit");

      final List<String> removing = new ArrayList<String>();
      // need to create a copy of the oldest lease paths, becuase 
      // internalReleaseLease() removes paths corresponding to empty files,
      // i.e. it needs to modify the collection being iterated over
      // causing ConcurrentModificationException
      String[] leasePaths = new String[oldest.getPaths().size()];
      oldest.getPaths().toArray(leasePaths);
      for(String p : leasePaths) {
        try {
          fsnamesystem.internalReleaseLeaseOne(oldest, p);
        } catch (IOException e) {
          LOG.error("Cannot release the path "+p+" in the lease "+oldest, e);
          removing.add(p);
        }
      }
      +
      ...
      +
        /**
   * Write an operation to the edit log. Do not sync to persistent
   * store yet.
   */
  synchronized void logEdit(byte op, Writable ... writables) {
    assert this.getNumEditStreams() > 0 : "no editlog streams";
    long start = FSNamesystem.now();
    for (int idx = 0; idx < editStreams.size(); idx++) {
      EditLogOutputStream eStream = editStreams.get(idx);
      try {
        eStream.write(op, writables);





